---
title: "딥러닝과 음성 데이터셋"
tags: audio-recognition dataset
---

작성자: 김우진


# 딥러닝
**딥러닝**이란 머신러닝의 한 방법으로, 학습 과정 동안 여러 층을 가진 인공신경망(ANN, Artificial Neural Network)을 사용하여 예시 데이터에서 얻은 규칙을 통해 데이터를 예측하는 기술입니다. 많은 일반적인 사람들은 딥러닝이라는 기술을 알파고를 통해 알게되었습니다. 하지만, 딥러닝의 시작은 2012년부터 였습니다.

## 이미지넷
![Imagenet](/assets/Imagenet.jpg)
2007년부터 시작된 [이미지넷 프로젝트](https://www.image-net.org)는 컴퓨터에게 이미지를 이해시키는 것에 대한 연구를 하기 위해서 시작되었습니다. 이미지넷 프로젝트는 컴퓨터를 이해시키기 위해서 인터넷에서 약 10억 장의 이미지를 구했고, 이를 오픈소스로 공개했습니다.

2010년부터는 이 데이터베이스를 바탕으로 **이미지넷 챌린지**(ILSVRC, ImageNet Large Scale Visual Recognition Challenge)가 진행되었습니다. 이미지넷 챌린지에서 2010년에는 오류율 28%, 2011년에는 오류율 26%인 팀이 우승을 차지했습니다. 많은 사람들이 더 이상의 획기적인 성능 개선은 어려울 것이라고 생각했습니다. 

하지만 놀랍게도, 작년 우승팀 대비 정확도가 10% 이상 늘어난 **알렉스넷**(AlexNet)이 등장했습니다. 알렉스넷은 뇌 구조를 본 딴 인공신경망 모델인 합성곱 신경망(CNN, Convolutional Neural Network)을 사용해 심층 신경망(DNN, Deep Neural Network)을 구현했습니다. 이것이 바로 딥러닝의 시작이었습니다.

![Alexnet-result](/assets/Alexnet-result.png)

# 음성인식
이러한 알렉스넷의 이미지넷 챌린지 우승이 딥러닝에서 가장 중요한 마일스톤 중 하나로 인식되고 있지만, 실제 딥러닝이 응용도메인에서 가장 먼저 획기적인 성능 향상을 가지고 온 것은 **음성인식**(ASR, Audio Speech Recognition) 분야입니다.

딥러닝 기반의 음성인식 기술이 발표된 이후로 AI비서 플랫폼을 포함한 다양한 음성인식 서비스에 딥러닝 기술이 적용되어 있습니다. 또한, 최근에는 온디바이스 환경에서 End-to-End 형태의 음성인식 모델을 이용한 다양한 기술들이 적용되어 있습니다.

이러한 음성인식 모델을 개발하기 위한 데이터셋에 대해 알아보겠습니다. 음성과 관련된 데이터들은 [**오픈SLR**](http://www.openslr.org/resources.php) 프로젝트에서 체계적으로 제공되고 있는데, 오픈SLR 프로젝트에서 제공하는 데이터셋을 포함하여 음성인식 연구에 널리 활용되고 있는 음성 데이터셋들을 소개하고자 합니다.

## LibriSpeech
[**LibriSpeech**](http://www.openslr.org/12)는 현존 음성인식 연구에 있어서 가장 널리 사용되고 있는 대규모 영어 음성 데이터셋 중 하나로, 사용자 참여형 오디오북 프로젝트인 [LibriVox](https://librivox.org)의 결과물입니다. LibriSpeech는 16kHz로 샘플링된 약 1000시간 분량의 오디오북 데이터입니다. LibriVox 데이터는 긴 발화 시간을 갖는 오디오북이기 때문에 음성인식 학습에 적합하도록 다양한 전처리가 수행되어 있습니다. 또한, 여러 가지 형태의 데이터가 있기 때문에 필요한 데이터를 선택하여 사용할 수 있습니다. 데이터셋의 구성은 다음과 같습니다.


|    데이터셋     | 시간(h) | 화자당 시간(m) | 여성 화자 수 | 남성 화자 수 | 전체 화자 수 |
| :-------------: | :-----: | :------------: | :----------: | :----------: | :----------: |
|    Dev-clean    |   5.4   |       8        |      20      |      20      |      40      |
|   Test-clean    |   5.4   |       8        |      20      |      20      |      40      |
|    Dev-other    |   5.3   |       10       |      16      |      17      |      33      |
|   Test-other    |   5.1   |       10       |      17      |      16      |      33      |
| Train-clean-100 |  100.5  |       25       |     125      |     126      |     251      |
| Train-clean-360 |  363.6  |       25       |     439      |     482      |     921      |

## Libri-Light
[**Libri-Light**](https://github.com/facebookresearch/libri-light)는 LibriSpeech와 마찬가지로 LibriVox 오디오북 프로젝트에서 추출된 데이터셋입니다. 하지만 LibriSpeech와 달리 Libri-Light는 전사된 텍스트 정보가 매우 제한되거나 존재하지 않는 경우에서의 음성인식을 위한 데이터셋입니다. 이 때문에 기존 음성인식 데이터셋과 달리 전사된 텍스트 정보 대신 SNR, 화자 ID, 해당 발화의 오디오북 장르 정보 등이 태그로 주어집니다. 이를 통해 대량의 비지도학습과 소량의 레이블 데이터를 이용한 전이학습 및 준지도학습 기반의 음성인식 기술 연구에 적합한 데이터셋입니다. Libri-Light 데이터를 학습한 모델의 성능 평가는 LibriSpeech 데이터셋을 활용하게 됩니다. 데이터셋의 구성은 다음과 같습니다.

### 분류되지 않은 음성 데이터셋

| 데이터셋  |  시간(h)  | 책 수 | 파일 수 | 화자당 시간(h) | 총 화자 수 |
| :-------: | :-------: | :---: | :-----: | :------------: | :--------: |
| Unlab-60k | 577,706.4 | 9,860 | 219,041 |      7.84      |   7,439    |
| Unlab-6k  |  5,770.7  | 1,106 | 21,327  |      3.31      |   1,742    |
| Unlab-600 |   577.2   |  202  |  2,588  |      1.18      |    489     |

### 제한된 음성 데이터셋

| 데이터셋  | 시간(h) | 화자당 시간(m) | 여성 화자 수 | 남성 화자 수 | 총 화자 수 |
| :-------: | :-----: | :------------: | :----------: | :----------: | :--------: |
| Train-10h |   10    |       25       |      12      |      12      |     24     |
| Train-1h  |    1    |      2.5       |      12      |      12      |     24     |
| Train-10m |  10분   |      2.5       |      2       |      2       |     4      |

## LJ Speech
[**LJ Speech**](https://keithito.com/LJ-Speech-Dataset/)는 LibriSpeech와 마찬가지로 LibriVox 오디오북 프로젝트에서 추출된 데이터셋입니다. 단일 화자가 발화한 7개의 비소설 오디오북으로부터 추출된 13,100개의 짧은 오디오클립으로 구성되어 있으며 각 클립마다 전사된 텍스트가 제공됩니다. 각 클립의 길이는 1~10초까지 다양하며 약 24시간 분량입니다. LibriSpeech가 다양한 화자로 구성된 반면 LJ Speech는 단일 화자, 24시간 이상의 분량으로 음성합성 연구에서 많이 활용되고 있습니다. 데이터의 통계치는 다음과 같습니다.

|    <!-- -->    | <!-- -->  |       <!-- -->       |  <!-- -->   |
| :------------: | :-------: | :------------------: | :---------: |
|   총 클립 수   |  13,100   |      총 단어 수      |   224,715   |
|   총 글자 수   | 1,308,678 |     총 클립 시간     | 23시간 55분 |
| 평균 클립 길이 |  6.57초   |    최소 클립 길이    |   1.11초    |
| 최대 클립 길이 |  10.1초   | 클립 당 평균 단어 수 |    17.23    |
|  고유 단어 수  |  13,821   |                      |             |

-----

다양한 데이터셋들의 특징을 알고, 자신에게 필요한 데이터셋을 사용한다면 좋은 모델을 얻어낼 수 있을 것입니다.